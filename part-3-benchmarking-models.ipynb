{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7052f9",
   "metadata": {},
   "source": [
    "# Hands-on session with pke - part 3\n",
    "\n",
    "This notebook provides an end-to-end example of model benchmarking on Inspec, a commonly-used dataset for keyphrase extraction that contains bibliographic records (i.e. title/abstract from scientific papers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c805385",
   "metadata": {},
   "source": [
    "## Preamble on keyphrase extraction datasets using ðŸ¤— datasets\n",
    "\n",
    "For simplicity and ease of use, we rely on the `datasets` module from ðŸ¤— huggingface to load and access sample documents from the inspec dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b0a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset inspec (/Users/boudin-f/.cache/huggingface/datasets/boudinfl___inspec/all/1.0.1/f333b3e8c7190f09ecbc2eee2706f13dd7370a0f3d72bb15ceb6e34ee90a6aa7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f010521288461fa05464aa22f3d239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2007\n",
      "title: The creation of a high-fidelity finite element mod...\n",
      "abstract: A detailed finite element model of the human kidne...\n",
      "gold-standard keyphrases: high-fidelity finite element model; kidney; trauma research; ...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the inspec dataset\n",
    "dataset = load_dataset('boudinfl/inspec', \"all\")\n",
    "\n",
    "# let's have a look at one sample document from the validation split\n",
    "sample = dataset[\"test\"][0]\n",
    "\n",
    "print(\"id: {}\".format(sample[\"id\"]))\n",
    "print(\"title: {}...\".format(sample[\"title\"][:50]))\n",
    "print(\"abstract: {}...\".format(sample[\"abstract\"][:50]))\n",
    "print(\"gold-standard keyphrases: {}; ...\".format(\"; \".join(sample[\"uncontr\"][:3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c92c7",
   "metadata": {},
   "source": [
    "## Benchmarking models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7006d9",
   "metadata": {},
   "source": [
    "### step-1: let's start by preprocessing the dataset using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7794153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2dfe9e236324ee5b18cf63ad9bcf615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.tokenizer import _get_regex_pattern\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenization fix for in-word hyphens (e.g. 'non-linear' would be kept \n",
    "# as one token instead of default spacy behavior of 'non', '-', 'linear')\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "re_token_match = f\"({re_token_match}|\\w+-\\w+)\"\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match\n",
    "\n",
    "# populates a docs list with spacy doc objects\n",
    "docs = []\n",
    "for sample in tqdm(dataset['test']):\n",
    "    docs.append(nlp(sample[\"title\"]+\". \"+sample[\"abstract\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7788966",
   "metadata": {},
   "source": [
    "### step-2: run the desired models on the dataset and store extracted keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a91a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f9063e5d2a4af59e48acfe33252d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b5d29d32f4571b4a86efec2ae3aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215b692780374c9a93b7ff2714a8c3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5523c4aecf4430a7029759331dee32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pke.unsupervised import *\n",
    "\n",
    "outputs = {}\n",
    "for model in [FirstPhrases, TopicRank, PositionRank, MultipartiteRank]:\n",
    "    outputs[model.__name__] = []\n",
    "    \n",
    "    extractor = model()\n",
    "    for i, doc in enumerate(tqdm(docs)):\n",
    "        extractor.load_document(input=doc, language='en')\n",
    "        extractor.grammar_selection(grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\")\n",
    "        extractor.candidate_weighting()\n",
    "        outputs[model.__name__].append([u for u,v in extractor.get_n_best(n=5, stemming=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8061c66",
   "metadata": {},
   "source": [
    "### step-3: evaluate the performance of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f96ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9f635ee4d54582859573a8e4fff6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FirstPhrases P@5: 0.336 R@5: 0.204 F@5: 0.239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8322f05933b4f74a10160e449f7d8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: TopicRank P@5: 0.345 R@5: 0.207 F@5: 0.243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551fb4c3820c4d22aa519864300b7ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: PositionRank P@5: 0.386 R@5: 0.239 F@5: 0.277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cafd721bbaf4f4b97495e0866cd893f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultipartiteRank P@5: 0.354 R@5: 0.211 F@5: 0.249\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate(top_N_keyphrases, references):\n",
    "    P = len(set(top_N_keyphrases) & set(references)) / len(top_N_keyphrases)\n",
    "    R = len(set(top_N_keyphrases) & set(references)) / len(references)\n",
    "    F = (2*P*R)/(P+R) if (P+R) > 0 else 0 \n",
    "    return (P, R, F)\n",
    "\n",
    "# loop through the models\n",
    "for model in outputs:\n",
    "    \n",
    "    # compute the P, R, F scores for the model\n",
    "    scores = []\n",
    "    for i, output in enumerate(tqdm(outputs[model])):\n",
    "        references = dataset['test'][i][\"uncontr_stems\"]\n",
    "        scores.append(evaluate(output, references))\n",
    "    \n",
    "    # compute the average scores\n",
    "    avg_scores = np.mean(scores, axis=0)\n",
    "    \n",
    "    # print out the performance of the model\n",
    "    print(\"Model: {} P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(model, avg_scores[0], avg_scores[1], avg_scores[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
