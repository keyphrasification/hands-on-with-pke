{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b764ffc9",
   "metadata": {},
   "source": [
    "# Hands-on session with pke - part 2\n",
    "\n",
    "This notebook provides a series of examples on how to parameterize the keyphrase extraction models in `pke`.\n",
    "More specifically, we will see how to customize the identification of keyphrase candidates and how to use different models implemented in `pke`.\n",
    "\n",
    "In a second time, we will conduct a series of experiments to compare several models on Inspec, a commonly-used benchmark dataset for keyphrase extraction that contains bibliographic records (i.e. title/abstract from scientific papers).\n",
    "\n",
    "As a reminder, `pke` provides a standardized API for extracting keyphrases from a document by typing the following 5 lines:\n",
    "\n",
    "```python\n",
    "import pke\n",
    "\n",
    "extractor = pke.unsupervised.TfIdf()        # initialize a keyphrase extraction model, here TFxIDF\n",
    "extractor.load_document(input='text')       # load the content of the document (file or str)\n",
    "extractor.candidate_selection()             # identify keyphrase candidates\n",
    "extractor.candidate_weighting()             # weight keyphrase candidates\n",
    "keyphrases = extractor.get_n_best(n=5)      # select the 5-best candidates as keyphrases\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c76acf",
   "metadata": {},
   "source": [
    "## Preamble on keyphrase extraction datasets using ðŸ¤— datasets\n",
    "\n",
    "For simplicity and ease of use, we rely on the `datasets` module from ðŸ¤— huggingface to load and access sample documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "446ebf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset inspec/all to /Users/boudin-f/.cache/huggingface/datasets/boudinfl___inspec/all/1.0.1/f333b3e8c7190f09ecbc2eee2706f13dd7370a0f3d72bb15ceb6e34ee90a6aa7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bddf77c18e45b4825dc674f6ff5f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1937e0230184b33be73f512ad5c597f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset inspec downloaded and prepared to /Users/boudin-f/.cache/huggingface/datasets/boudinfl___inspec/all/1.0.1/f333b3e8c7190f09ecbc2eee2706f13dd7370a0f3d72bb15ceb6e34ee90a6aa7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e77cb6fecf4a41b91332b9b6ab8f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1895\n",
      "title: An algorithm combining neural networks with fundam...\n",
      "abstract: An algorithm combining neural networks with the fu...\n",
      "controlled keyphrases: chromium alloys; iron alloys; neural nets; ...\n",
      "uncontrolled keyphrases: algorithm; neural networks; fundamental parameters; ...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the inspec dataset\n",
    "dataset = load_dataset('boudinfl/inspec', \"all\")\n",
    "\n",
    "# let's have a look at one sample document from the validation split\n",
    "sample = dataset[\"validation\"][233]\n",
    "\n",
    "print(\"id: {}\".format(sample[\"id\"]))\n",
    "print(\"title: {}...\".format(sample[\"title\"][:50]))\n",
    "print(\"abstract: {}...\".format(sample[\"abstract\"][:50]))\n",
    "print(\"controlled keyphrases: {}; ...\".format(\"; \".join(sample[\"contr\"][:3])))\n",
    "print(\"uncontrolled keyphrases: {}; ...\".format(\"; \".join(sample[\"uncontr\"][:3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c9b2c",
   "metadata": {},
   "source": [
    "## Model parameterization - candidate selection\n",
    "\n",
    "Candidate selection is a crucial stage in keyphrase extraction as it determines the size of the search space (i.e. number of candidates to rank/weight) and the upper bound performance (i.e. maximum recall).\n",
    "Here, we will see how to configure the candidate selection method in `pke` to achieve the best compromise between search space and maximum performance.\n",
    "\n",
    "In order to compare candidate selection methods, we compute the maximum recall score against the gold standard (human-assigned) keyphrases as\n",
    "\n",
    "$$max\\_recall = \\frac{| candidates \\cap references|}{|references|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59a7af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pke\n",
    "\n",
    "# initialize a simple model that ranks candidates using their position\n",
    "extractor = pke.unsupervised.FirstPhrases()\n",
    "\n",
    "# the text to process is the title concatenated to the abstract\n",
    "text = sample[\"title\"] + \". \" + sample[\"abstract\"]\n",
    "\n",
    "# the references in stemmed form to compute the maximum recall\n",
    "references = sample[\"uncontr_stems\"]\n",
    "\n",
    "# load the document using the initialized model\n",
    "extractor.load_document(input=text, language='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b3525",
   "metadata": {},
   "source": [
    "### Setting up a linguistic-based selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09c64d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 keyphrase candidates were identified\n",
      "- Subsample of candidates: algorithm ; neural network ; fundament paramet ; fundament paramet equat ; nnfp\n",
      "- Maximum recall: 0.765\n",
      "- Missed reference keyphrases: {'theoret correct model', 'lachance-trail model', 'x-ray fluoresc analysi', 'nonlinear matrix effect'}\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "                NP:\n",
    "                    {<ADJ>*<NOUN|PROPN>+}\n",
    "            \"\"\"\n",
    "\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "\n",
    "# let's see how many candidates are identified\n",
    "print(\"{} keyphrase candidates were identified\".format(len(extractor.candidates)))\n",
    "\n",
    "# print out a sample\n",
    "candidates = [*extractor.candidates]\n",
    "print(\"- Subsample of candidates:\", ' ; '.join(candidates[:5]))\n",
    "\n",
    "# compute the maximum recall\n",
    "max_recall = len(set(references) & set(candidates)) / len(set(references))\n",
    "print(\"- Maximum recall: {:.3f}\".format(max_recall))\n",
    "\n",
    "# identify missed reference keyphrases\n",
    "missed = set(references) - set(candidates)\n",
    "print(\"- Missed reference keyphrases: {}\".format(missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b6b7b",
   "metadata": {},
   "source": [
    "<span style=\"background:lightpink\">\n",
    "    Exercice: try modifying/adding PoS patterns of the grammar to increase the maximum recall.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502c893",
   "metadata": {},
   "source": [
    "### Setting up a n-gram-based selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74271ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 keyphrase candidates were identified\n",
      "- Subsample of candidates: an ; an algorithm ; an algorithm combin ; algorithm ; algorithm combin\n",
      "- Maximum recall: 0.824\n",
      "- Missed reference keyphrases: {'lachance-trail model', 'x-ray fluoresc analysi', 'nonlinear matrix effect'}\n"
     ]
    }
   ],
   "source": [
    "# first we need to empty the candidates\n",
    "extractor.candidates.clear()\n",
    "\n",
    "# here we use a simple n-gram selection for candidates\n",
    "extractor.ngram_selection(n=3)\n",
    "\n",
    "# let's see how many candidates are identified\n",
    "print(\"{} keyphrase candidates were identified\".format(len(extractor.candidates)))\n",
    "\n",
    "# print out a sample\n",
    "candidates = [*extractor.candidates]\n",
    "print(\"- Subsample of candidates:\", ' ; '.join(candidates[:5]))\n",
    "\n",
    "# compute the maximum recall\n",
    "max_recall = len(set(references) & set(candidates)) / len(set(references))\n",
    "print(\"- Maximum recall: {:.3f}\".format(max_recall))\n",
    "\n",
    "# identify missed reference keyphrases\n",
    "missed = set(references) - set(candidates)\n",
    "print(\"- Missed reference keyphrases: {}\".format(missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f45788c",
   "metadata": {},
   "source": [
    "<span style=\"background:lightpink\">\n",
    "    Exercice: try removing unrelevant candidates to reduce the search space.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7b4fd",
   "metadata": {},
   "source": [
    "## Model parameterization - candidate weighting/ranking\n",
    "\n",
    "The keyphrase extraction model that we use in `pke` define how candidates are weighted. For example, in TopicRank, candidates are weighted using a graph-based ranking model whereas in Yake, candidates are weighted using a combination of statistical features (e.g. position, frequency). Here, we will see how to use different models implemented in `pke`. For comparison purposes, we will use a unified candidate selection method (as presented above). Models are evaluated against the gold standard (human-assigned) keyphrases by computing the precision, recall and f-measure at the top-N extracted keyphases as:\n",
    "\n",
    "$$ precision@N = \\frac{| top-N candidates \\cap references|}{|top-N candidates|} $$\n",
    "\n",
    "$$ recall@N = \\frac{| top-N candidates \\cap references|}{|references|} $$\n",
    "\n",
    "$$ f-measure@N = 2 \\times \\frac{precision@N \\cdot recall@N }{precision@N + recall@N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5f8dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the text to process is the title concatenated to the abstract\n",
    "text = sample[\"title\"] + \". \" + sample[\"abstract\"]\n",
    "\n",
    "# the unified grammar for candidate selection\n",
    "grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe47114",
   "metadata": {},
   "source": [
    "### Baseline model: TopicRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65925f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 keyphrases: fundament paramet; nnfp; classic theoret correct model; algorithm; non - linear matrix effect\n",
      "P@5: 0.400 R@5: 0.118 F@5: 0.182\n"
     ]
    }
   ],
   "source": [
    "extractor = pke.unsupervised.TopicRank()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8428ef",
   "metadata": {},
   "source": [
    "### Good performance graph-based ranking model: MultipartiteRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0cce756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 keyphrases: fundament paramet; algorithm; neural network; nnfp; classic theoret correct model\n",
      "P@5: 0.600 R@5: 0.176 F@5: 0.273\n"
     ]
    }
   ],
   "source": [
    "extractor = pke.unsupervised.MultipartiteRank()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c4f711",
   "metadata": {},
   "source": [
    "### Supervised model: Kea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68245b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:LoadFile._df_counts is hard coded to /Users/boudin-f/Documents/GitHub/hands-on-with-pke/venv/lib/python3.10/site-packages/pke/models/df-semeval2010.tsv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 keyphrases: nnfp algorithm; neural network; fundament paramet; fundament paramet equat; non - linear matrix effect\n",
      "P@5: 0.800 R@5: 0.235 F@5: 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boudin-f/Documents/GitHub/hands-on-with-pke/venv/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.20.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "extractor = pke.supervised.Kea()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7546e05",
   "metadata": {},
   "source": [
    "<span style=\"background:lightpink\">\n",
    "    Exercice: try using another model.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3216c49",
   "metadata": {},
   "source": [
    "## Benchmarking models on the inspec dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8592ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
