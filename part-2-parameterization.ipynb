{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b764ffc9",
   "metadata": {},
   "source": [
    "# Hands-on session with pke - part 2\n",
    "\n",
    "This notebook provides a series of examples on how to parameterize the keyphrase extraction models in `pke`.\n",
    "More specifically, we will see how to customize the identification of keyphrase candidates and how to use different models implemented in `pke`.\n",
    "\n",
    "In a second time, we will conduct a series of experiments to compare several models on Inspec, a commonly-used benchmark dataset for keyphrase extraction that contains bibliographic records (i.e. title/abstract from scientific papers).\n",
    "\n",
    "As a reminder, `pke` provides a standardized API for extracting keyphrases from a document by typing the following 5 lines:\n",
    "\n",
    "```python\n",
    "import pke\n",
    "\n",
    "extractor = pke.unsupervised.TfIdf()        # initialize a keyphrase extraction model, here TFxIDF\n",
    "extractor.load_document(input='text')       # load the content of the document (str or spacy Doc)\n",
    "extractor.candidate_selection()             # identify keyphrase candidates\n",
    "extractor.candidate_weighting()             # weight keyphrase candidates\n",
    "keyphrases = extractor.get_n_best(n=5)      # select the 5-best candidates as keyphrases\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c76acf",
   "metadata": {},
   "source": [
    "## Preamble on keyphrase extraction datasets using ü§ó datasets\n",
    "\n",
    "For simplicity and ease of use, we rely on the `datasets` module from ü§ó huggingface to load and access sample documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446ebf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset inspec (/Users/boudin-f/.cache/huggingface/datasets/boudinfl___inspec/all/1.0.1/f333b3e8c7190f09ecbc2eee2706f13dd7370a0f3d72bb15ceb6e34ee90a6aa7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93315ede72124fc585bc37561d7d11a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1895\n",
      "title: An algorithm combining neural networks with fundam...\n",
      "abstract: An algorithm combining neural networks with the fu...\n",
      "controlled keyphrases: chromium alloys; iron alloys; neural nets; ...\n",
      "uncontrolled keyphrases: algorithm; neural networks; fundamental parameters; ...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the inspec dataset\n",
    "dataset = load_dataset('boudinfl/inspec', \"all\")\n",
    "\n",
    "# let's have a look at one sample document from the validation split\n",
    "sample = dataset[\"validation\"][233]\n",
    "\n",
    "print(\"id: {}\".format(sample[\"id\"]))\n",
    "print(\"title: {}...\".format(sample[\"title\"][:50]))\n",
    "print(\"abstract: {}...\".format(sample[\"abstract\"][:50]))\n",
    "print(\"controlled keyphrases: {}; ...\".format(\"; \".join(sample[\"contr\"][:3])))\n",
    "print(\"uncontrolled keyphrases: {}; ...\".format(\"; \".join(sample[\"uncontr\"][:3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c9b2c",
   "metadata": {},
   "source": [
    "## Model parameterization - candidate selection\n",
    "\n",
    "Candidate selection is a crucial stage in keyphrase extraction as it determines the size of the search space (i.e. number of candidates to rank/weight) and the upper bound performance (i.e. maximum recall).\n",
    "Here, we will see how to configure the candidate selection method in `pke` to achieve the best compromise between search space and maximum performance.\n",
    "\n",
    "In order to compare candidate selection methods, we compute the maximum recall score against the gold standard (human-assigned) keyphrases as\n",
    "\n",
    "$$max\\_recall = \\frac{| candidates \\cap references|}{|references|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb66d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pke\n",
    "\n",
    "# initialize a simple model that ranks candidates using their position\n",
    "extractor = pke.unsupervised.FirstPhrases()\n",
    "\n",
    "# the text to process is the title concatenated to the abstract\n",
    "text = sample[\"title\"] + \". \" + sample[\"abstract\"]\n",
    "\n",
    "# the references in stemmed form to compute the maximum recall\n",
    "references = sample[\"uncontr_stems\"]\n",
    "\n",
    "# load the document using the initialized model\n",
    "extractor.load_document(input=text, language='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b3525",
   "metadata": {},
   "source": [
    "### Setting up a linguistic-based selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00cf6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 keyphrase candidates were identified\n",
      "- Subsample of candidates: algorithm ; network ; paramet ; paramet equat ; nnfp\n",
      "- Maximum recall: 0.529\n",
      "- Missed reference keyphrases: {'neural network', 'hyperbol function model', 'fundament paramet', 'nonlinear matrix effect', 'fundament paramet equat', 'complex multivari system', 'lachance-trail model', 'theoret correct model'}\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "                NP:\n",
    "                    {<NOUN|PROPN>+}\n",
    "            \"\"\"\n",
    "\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "\n",
    "# let's see how many candidates are identified\n",
    "print(\"{} keyphrase candidates were identified\".format(len(extractor.candidates)))\n",
    "\n",
    "# print out a sample\n",
    "candidates = [*extractor.candidates]\n",
    "print(\"- Subsample of candidates:\", ' ; '.join(candidates[:5]))\n",
    "\n",
    "# compute the maximum recall\n",
    "max_recall = len(set(references) & set(candidates)) / len(set(references))\n",
    "print(\"- Maximum recall: {:.3f}\".format(max_recall))\n",
    "\n",
    "# identify missed reference keyphrases\n",
    "missed = set(references) - set(candidates)\n",
    "print(\"- Missed reference keyphrases: {}\".format(missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242bc76",
   "metadata": {},
   "source": [
    "### <span style=\"background:lightpink\">Exercice ‚úçÔ∏è</span>\n",
    "\n",
    "try modifying/adding PoS patterns of the grammar to increase the maximum recall, for example by allowing predicative adjectives (e.g. `<ADJ>+`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502c893",
   "metadata": {},
   "source": [
    "### Setting up a n-gram-based selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74271ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 keyphrase candidates were identified\n",
      "- Subsample of candidates: an ; an algorithm ; an algorithm combin ; algorithm ; algorithm combin\n",
      "- Maximum recall: 0.941\n",
      "- Missed reference keyphrases: {'nonlinear matrix effect'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# here we use a simple n-gram selection for candidates\n",
    "extractor.ngram_selection(n=3)\n",
    "\n",
    "# filter out spurious candidates \n",
    "for i, candidate in enumerate(list(extractor.candidates.keys())):\n",
    "    # remove if containing punctuation marks\n",
    "    if re.search(r'\\.|\\?|\\!|\\,', candidate):\n",
    "        del extractor.candidates[candidate]\n",
    "\n",
    "# let's see how many candidates are identified\n",
    "print(\"{} keyphrase candidates were identified\".format(len(extractor.candidates)))\n",
    "\n",
    "# print out a sample\n",
    "candidates = [*extractor.candidates]\n",
    "print(\"- Subsample of candidates:\", ' ; '.join(candidates[:5]))\n",
    "\n",
    "# compute the maximum recall\n",
    "max_recall = len(set(references) & set(candidates)) / len(set(references))\n",
    "print(\"- Maximum recall: {:.3f}\".format(max_recall))\n",
    "\n",
    "# identify missed reference keyphrases\n",
    "missed = set(references) - set(candidates)\n",
    "print(\"- Missed reference keyphrases: {}\".format(missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa593ce7",
   "metadata": {},
   "source": [
    "### <span style=\"background:lightpink\">Exercice ‚úçÔ∏è</span>\n",
    "\n",
    "try removing unrelevant candidates to reduce the search space by adding constraints in the filtering process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7b4fd",
   "metadata": {},
   "source": [
    "## Model parameterization - candidate weighting/ranking\n",
    "\n",
    "The keyphrase extraction model that we use in `pke` define how candidates are weighted. For example, in TopicRank, candidates are weighted using a graph-based ranking model whereas in Yake, candidates are weighted using a combination of statistical features (e.g. position, frequency). Here, we will see how to use different models implemented in `pke`. For comparison purposes, we will use a unified candidate selection method (as presented above). Models are evaluated against the gold standard (human-assigned) keyphrases by computing the precision, recall and f-measure at the top-N extracted keyphases as:\n",
    "\n",
    "$$ precision@N = \\frac{| top-N candidates \\cap references|}{|top-N candidates|} $$\n",
    "\n",
    "$$ recall@N = \\frac{| top-N candidates \\cap references|}{|references|} $$\n",
    "\n",
    "$$ f-measure@N = 2 \\times \\frac{precision@N \\cdot recall@N }{precision@N + recall@N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7881fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the text to process is the title concatenated to the abstract\n",
    "text = sample[\"title\"] + \". \" + sample[\"abstract\"]\n",
    "\n",
    "# the unified grammar for candidate selection\n",
    "grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe47114",
   "metadata": {},
   "source": [
    "### Baseline model: TopicRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65925f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 keyphrases: fundament paramet; nnfp; algorithm; classic theoret correct model; non-linear matrix effect\n",
      "P@5: 0.400 R@5: 0.118 F@5: 0.182\n"
     ]
    }
   ],
   "source": [
    "extractor = pke.unsupervised.TopicRank()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8428ef",
   "metadata": {},
   "source": [
    "### A better graph-based model: MultipartiteRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0cce756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 keyphrases: nnfp algorithm; neural network; fundament paramet; fundament paramet equat; fundament paramet approach\n",
      "P@5: 0.800 R@5: 0.235 F@5: 0.364\n"
     ]
    }
   ],
   "source": [
    "extractor = pke.unsupervised.YAKE()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c4f711",
   "metadata": {},
   "source": [
    "### Supervised model: Kea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68245b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:LoadFile._df_counts is hard coded to /Users/boudin-f/Documents/GitHub/hands-on-with-pke/venv/lib/python3.10/site-packages/pke/models/df-semeval2010.tsv.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 keyphrases: nnfp algorithm; neural network; fundament paramet; fundament paramet equat; non-linear matrix effect\n",
      "P@5: 0.800 R@5: 0.235 F@5: 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boudin-f/Documents/GitHub/hands-on-with-pke/venv/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.20.0 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "extractor = pke.supervised.Kea()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25d04a",
   "metadata": {},
   "source": [
    "<span style=\"background:lightpink\">\n",
    "    Exercice: try using another model.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3216c49",
   "metadata": {},
   "source": [
    "## Benchmarking models on the inspec dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86eec04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e16edbb2ab4b4b8b2fc76e75337a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocessing the dataset using spacy\n",
    "import re\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm\n",
    "from spacy.tokenizer import _get_regex_pattern\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenization fix for in-word hyphens (e.g. non-linear is kept as one token)\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "re_token_match = f\"({re_token_match}|\\w+-\\w+)\"\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match\n",
    "\n",
    "docs = []\n",
    "for sample in tqdm(dataset['test']):\n",
    "    docs.append(nlp(sample[\"title\"]+\". \"+sample[\"abstract\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8592ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546347a367294a3d8cf2b32774209381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract keyphrases\n",
    "keyphrases = []\n",
    "for i, doc in enumerate(tqdm(docs)):\n",
    "    extractor = pke.unsupervised.FirstPhrases()\n",
    "    extractor.load_document(input=doc, language='en')\n",
    "    extractor.grammar_selection(grammar=grammar)\n",
    "    extractor.candidate_weighting()\n",
    "    keyphrases.append([u for u,v in extractor.get_n_best(n=5, stemming=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c1a06bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1961f271f94586ac4c7fc076c4e7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@5: 0.336 R@5: 0.204 F@5: 0.239\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# evaluate keyphrases\n",
    "scores = []\n",
    "for i, output in enumerate(tqdm(keyphrases)):\n",
    "    references = dataset['test'][i][\"uncontr_stems\"]\n",
    "    P = len(set(output) & set(references)) / len(output)\n",
    "    R = len(set(output) & set(references)) / len(references)\n",
    "    F = 0.0\n",
    "    if (P+R) > 0:\n",
    "        F = 2 * (P*R) / (P+R)\n",
    "    scores.append((P, R, F))\n",
    "\n",
    "avg_scores = np.mean(scores, axis=0)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(avg_scores[0], avg_scores[1], avg_scores[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d5862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
