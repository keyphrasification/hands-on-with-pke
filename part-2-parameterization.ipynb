{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b764ffc9",
   "metadata": {},
   "source": [
    "# Hands-on session with pke - part 2\n",
    "\n",
    "This notebook provides a series of examples on how to parameterize the keyphrase extraction models in `pke`.\n",
    "More specifically, we will see how to customize the identification of keyphrase candidates and how to use different models implemented in `pke`.\n",
    "\n",
    "In a second time, we will conduct a series of experiments to compare several models on Inspec, a commonly-used benchmark dataset for keyphrase extraction that contains bibliographic records (i.e. title/abstract from scientific papers).\n",
    "\n",
    "As a reminder, `pke` provides a standardized API for extracting keyphrases from a document by typing the following 5 lines:\n",
    "\n",
    "```python\n",
    "import pke\n",
    "\n",
    "extractor = pke.unsupervised.TfIdf()        # initialize a keyphrase extraction model, here TFxIDF\n",
    "extractor.load_document(input='text')       # load the content of the document (file or str)\n",
    "extractor.candidate_selection()             # identify keyphrase candidates\n",
    "extractor.candidate_weighting()             # weight keyphrase candidates\n",
    "keyphrases = extractor.get_n_best(n=5)      # select the 5-best candidates as keyphrases\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c76acf",
   "metadata": {},
   "source": [
    "## Preamble on keyphrase extraction datasets using ðŸ¤— datasets\n",
    "\n",
    "For simplicity and ease of use, we rely on the `datasets` module from ðŸ¤— huggingface to load and access sample documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446ebf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset inspec (/Users/boudin-f/.cache/huggingface/datasets/boudinfl___inspec/all/1.0.1/f333b3e8c7190f09ecbc2eee2706f13dd7370a0f3d72bb15ceb6e34ee90a6aa7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97878c22db7b4bb2b4c2c1df0a57973c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1895\n",
      "title: An algorithm combining neural networks with fundam...\n",
      "abstract: An algorithm combining neural networks with the fu...\n",
      "controlled keyphrases: chromium alloys; iron alloys; neural nets; ...\n",
      "uncontrolled keyphrases: algorithm; neural networks; fundamental parameters; ...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the inspec dataset\n",
    "dataset = load_dataset('boudinfl/inspec', \"all\")\n",
    "\n",
    "# let's have a look at one sample document from the validation split\n",
    "sample = dataset[\"validation\"][233]\n",
    "\n",
    "print(\"id: {}\".format(sample[\"id\"]))\n",
    "print(\"title: {}...\".format(sample[\"title\"][:50]))\n",
    "print(\"abstract: {}...\".format(sample[\"abstract\"][:50]))\n",
    "print(\"controlled keyphrases: {}; ...\".format(\"; \".join(sample[\"contr\"][:3])))\n",
    "print(\"uncontrolled keyphrases: {}; ...\".format(\"; \".join(sample[\"uncontr\"][:3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c9b2c",
   "metadata": {},
   "source": [
    "## Model parameterization - candidate selection\n",
    "\n",
    "Candidate selection is a crucial stage in keyphrase extraction as it determines the size of the search space (i.e. number of candidates to rank/weight) and the upper bound performance (i.e. maximum recall).\n",
    "Here, we will see how to configure the candidate selection method in `pke` to achieve the best compromise between search space and maximum performance.\n",
    "\n",
    "In order to compare candidate selection methods, we compute the maximum recall score against the gold standard (human-assigned) keyphrases as\n",
    "\n",
    "$$max\\_recall = \\frac{| candidates \\cap references|}{|references|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1ac84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pke\n",
    "\n",
    "# initialize a simple model that ranks candidates using their position\n",
    "extractor = pke.unsupervised.FirstPhrases()\n",
    "\n",
    "# the text to process is the title concatenated to the abstract\n",
    "text = sample[\"title\"] + \". \" + sample[\"abstract\"]\n",
    "\n",
    "# the references in stemmed form to compute the maximum recall\n",
    "references = sample[\"uncontr_stems\"]\n",
    "\n",
    "# load the document using the initialized model\n",
    "extractor.load_document(input=text, language='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b3525",
   "metadata": {},
   "source": [
    "### Setting up a linguistic-based selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5e440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 keyphrase candidates were identified\n",
      "- Subsample of candidates: algorithm ; neural network ; fundament paramet ; fundament paramet equat ; nnfp\n",
      "- Maximum recall: 0.765\n",
      "- Missed reference keyphrases: {'x-ray fluoresc analysi', 'theoret correct model', 'lachance-trail model', 'nonlinear matrix effect'}\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "                NP:\n",
    "                    {<ADJ>*<NOUN|PROPN>+}\n",
    "            \"\"\"\n",
    "\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "\n",
    "# let's see how many candidates are identified\n",
    "print(\"{} keyphrase candidates were identified\".format(len(extractor.candidates)))\n",
    "\n",
    "# print out a sample\n",
    "candidates = [*extractor.candidates]\n",
    "print(\"- Subsample of candidates:\", ' ; '.join(candidates[:5]))\n",
    "\n",
    "# compute the maximum recall\n",
    "max_recall = len(set(references) & set(candidates)) / len(set(references))\n",
    "print(\"- Maximum recall: {:.3f}\".format(max_recall))\n",
    "\n",
    "# identify missed reference keyphrases\n",
    "missed = set(references) - set(candidates)\n",
    "print(\"- Missed reference keyphrases: {}\".format(missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee250eb",
   "metadata": {},
   "source": [
    "<span style=\"background:lightpink\">\n",
    "    Exercice: try modifying/adding PoS patterns of the grammar to increase the maximum recall.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502c893",
   "metadata": {},
   "source": [
    "### Setting up a n-gram-based selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74271ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 keyphrase candidates were identified\n",
      "- Subsample of candidates: an ; an algorithm ; an algorithm combin ; algorithm ; algorithm combin\n",
      "- Maximum recall: 0.824\n",
      "- Missed reference keyphrases: {'x-ray fluoresc analysi', 'lachance-trail model', 'nonlinear matrix effect'}\n"
     ]
    }
   ],
   "source": [
    "# first we need to empty the candidates\n",
    "extractor.candidates.clear()\n",
    "\n",
    "# here we use a simple n-gram selection for candidates\n",
    "extractor.ngram_selection(n=3)\n",
    "\n",
    "# let's see how many candidates are identified\n",
    "print(\"{} keyphrase candidates were identified\".format(len(extractor.candidates)))\n",
    "\n",
    "# print out a sample\n",
    "candidates = [*extractor.candidates]\n",
    "print(\"- Subsample of candidates:\", ' ; '.join(candidates[:5]))\n",
    "\n",
    "# compute the maximum recall\n",
    "max_recall = len(set(references) & set(candidates)) / len(set(references))\n",
    "print(\"- Maximum recall: {:.3f}\".format(max_recall))\n",
    "\n",
    "# identify missed reference keyphrases\n",
    "missed = set(references) - set(candidates)\n",
    "print(\"- Missed reference keyphrases: {}\".format(missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d8ded",
   "metadata": {},
   "source": [
    "<span style=\"background:lightpink\">\n",
    "    Exercice: try removing unrelevant candidates to reduce the search space.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7b4fd",
   "metadata": {},
   "source": [
    "## Model parameterization - candidate weighting/ranking\n",
    "\n",
    "The keyphrase extraction model that we use in `pke` define how candidates are weighted. For example, in TopicRank, candidates are weighted using a graph-based ranking model whereas in Yake, candidates are weighted using a combination of statistical features (e.g. position, frequency). Here, we will see how to use different models implemented in `pke`. For comparison purposes, we will use a unified candidate selection method (as presented above). Models are evaluated against the gold standard (human-assigned) keyphrases by computing the precision, recall and f-measure at the top-N extracted keyphases as:\n",
    "\n",
    "$$ precision@N = \\frac{| top-N candidates \\cap references|}{|top-N candidates|} $$\n",
    "\n",
    "$$ recall@N = \\frac{| top-N candidates \\cap references|}{|references|} $$\n",
    "\n",
    "$$ f-measure@N = 2 \\times \\frac{precision@N \\cdot recall@N }{precision@N + recall@N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9ba82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the text to process is the title concatenated to the abstract\n",
    "text = sample[\"title\"] + \". \" + sample[\"abstract\"]\n",
    "\n",
    "# the unified grammar for candidate selection\n",
    "grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe47114",
   "metadata": {},
   "source": [
    "### Baseline model: TopicRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65925f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 keyphrases: fundament paramet; nnfp; classic theoret correct model; algorithm; non - linear matrix effect\n",
      "P@5: 0.400 R@5: 0.118 F@5: 0.182\n"
     ]
    }
   ],
   "source": [
    "extractor = pke.unsupervised.TopicRank()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8428ef",
   "metadata": {},
   "source": [
    "### Good performance graph-based ranking model: MultipartiteRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0cce756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 keyphrases: fundament paramet; algorithm; neural network; nnfp; classic theoret correct model\n",
      "P@5: 0.600 R@5: 0.176 F@5: 0.273\n"
     ]
    }
   ],
   "source": [
    "extractor = pke.unsupervised.MultipartiteRank()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c4f711",
   "metadata": {},
   "source": [
    "### Supervised model: Kea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68245b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = pke.supervised.Kea()\n",
    "extractor.load_document(input=text, language='en')\n",
    "extractor.grammar_selection(grammar=grammar)\n",
    "extractor.candidate_weighting()\n",
    "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
    "\n",
    "top5 = [candidate for candidate, weight in keyphrases]\n",
    "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
    "\n",
    "# evaluate the Precision / Recall / F-measure of the model\n",
    "P = len(set(top5) & set(references)) / len(top5)\n",
    "R = len(set(top5) & set(references)) / len(references)\n",
    "F = 2 * (P*R) / (P+R)\n",
    "print(\"P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(P, R, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649cf9c",
   "metadata": {},
   "source": [
    "<span style=\"background:lightpink\">\n",
    "    Exercice: try using another model.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3216c49",
   "metadata": {},
   "source": [
    "## Benchmarking models on the inspec dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8592ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the inspec dataset\n",
    "dataset = load_dataset('boudinfl/inspec', \"all\")\n",
    "\n",
    "\n",
    "# loop through the test split of the dataset and extract keyphrases\n",
    "scores = []\n",
    "for sample in dataset['test']:\n",
    "\n",
    "    extractor = pke.unsupervised.FirstPhrases()\n",
    "    extractor.load_document(input=sample[\"title\"]+\". \"+sample[\"abstract\"], language='en')\n",
    "    extractor.grammar_selection(grammar=grammar)\n",
    "    extractor.candidate_weighting()\n",
    "    \n",
    "    keyphrases = [u for u,v in extractor.get_n_best(n=5, stemming=True)]\n",
    "    references = sample[\"uncontr_stems\"]\n",
    "    \n",
    "    P = len(set(keyphrases) & set(references)) / len(keyphrases)\n",
    "    R = len(set(keyphrases) & set(references)) / len(references)\n",
    "    F = 0.0\n",
    "    if (P+R) > 0:\n",
    "        F = 2 * (P*R) / (P+R)\n",
    "    print(\"id: {} - P@5: {:.3f} R@5: {:.3f} F@5: {:.3f}\".format(sample[\"id\"], P, R, F))\n",
    "    \n",
    "    # memorize scores\n",
    "    scores.append([P, R, F])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
